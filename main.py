import sys
import os
import re
import traceback
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import FileResponse, JSONResponse, PlainTextResponse
from pydantic import BaseModel


# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), "module"))
from module.llm.llm_client import generate_emotion_from_prompt_with_context, generate_gpt_response_from_history
from module.utils.utils import load_history, append_history
from module.utils.utils import logger
from module.emotion.main_emotion import save_response_to_memory, write_structured_emotion_data
from module.emotion.emotion_stats import summarize_feeling
from module.emotion.emotion_stats import load_current_emotion
from module.response.main_response import find_response_by_emotion, get_best_match, collect_all_category_responses
from module.response.response_index import load_index
from module.emotion.emotion_stats import load_current_emotion, merge_emotion_vectors, save_current_emotion, summarize_feeling
from module.oblivion.oblivion_module import run_oblivion_cleanup_all

app = FastAPI()

class UserMessage(BaseModel):
    message: str

def sanitize_output_for_display(text: str) -> str:
    # JSONãƒ–ãƒ­ãƒƒã‚¯ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ§‹æˆã®å‰Šé™¤ï¼ˆæ•´å½¢æ¸ˆã¿ï¼‰
    text = re.sub(r"\n?json\s*\{.*?\}\s*\n?", "", text, flags=re.DOTALL)
    text = re.sub(r"\{\s*\"date\"\s*:\s*\".*?\".*?\"keywords\"\s*:\s*\[.*?\]\s*\}", "", text, flags=re.DOTALL)
    return text.strip()


@app.get("/")
def get_ui():
    return FileResponse("static/index.html")

@app.get("/history")
#éå»å±¥æ­´ã‚’ãƒãƒ£ãƒƒãƒˆæ¬„ã«å‘¼ã³å‡ºã—
def get_history():
    try:
        return {"history": load_history()}
    except Exception as e:
        logger.exception("å±¥æ­´å–å¾—ä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        raise HTTPException(status_code=500, detail="å±¥æ­´ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

@app.post("/chat")
async def chat(
    message: str = Form(...),
    file: UploadFile = File(None),
    background_tasks: BackgroundTasks = None
):
    logger.debug("âœ… /chat ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«åˆ°é”")
    logger.info("âœ… debug() å®Ÿè¡Œæ¸ˆã¿")

    try:
        user_input = message
        logger.debug(f"ğŸ“¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å–å¾—å®Œäº†: {user_input}")

        if file:
            logger.debug(f"ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å: {file.filename}")
            extracted_text = await handle_uploaded_file(file)
            if extracted_text:
                user_input += f"\n\n[æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹]:\n{extracted_text}"

        append_history("user", user_input)
        logger.debug("ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´è¿½åŠ å®Œäº†")

        logger.debug(f"â‘¡ç¾åœ¨æ„Ÿæƒ…ã‚’ãƒ­ãƒ¼ãƒ‰")
        index_data = load_index()
        current_emotion = load_current_emotion()
        logger.debug(f"ğŸ¯ [INFO] ç¾åœ¨æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«: {current_emotion}")

        response_text = generate_gpt_response_from_history()
        logger.info(f"ğŸ“¨ GPTå¿œç­”:\n{response_text}")

        emotion_data = find_response_by_emotion()

        if emotion_data["type"] == "extracted":
            logger.info("[STEP] GPTå¿œç­”ã‹ã‚‰æ§‹æˆæ¯”ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—æ¸ˆ")
            best_match = get_best_match(emotion_data)

            if best_match:
                logger.info("[STEP] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãƒãƒƒãƒã—ãŸå¿œç­”ã‚’å–å¾—")
                response_text = best_match.get("å¿œç­”", "")
                append_history("assistant", response_text)
            else:
                from datetime import datetime
                dominant_emotion = next(iter(emotion_data["æ§‹æˆæ¯”"]), None)
                if dominant_emotion:
                    today = datetime.now().strftime("%Y-%m-%d")
                    matched = collect_all_category_responses(
                        emotion_name=dominant_emotion,
                        date_str=today
                    )
                    for cat in ["short", "intermediate", "long"]:
                        if matched.get(cat):
                            response_text = matched[cat].get("å¿œç­”", "")
                            logger.info(f"[STEP] å±¥æ­´ã‹ã‚‰ {cat} ã‚«ãƒ†ã‚´ãƒªã®å¿œç­”ã‚’è¿”å´")
                            append_history("assistant", response_text)
                            break

                if not response_text:
                    logger.warning("[WARN] å±¥æ­´ã«ã‚‚ä¸€è‡´ã™ã‚‹å¿œç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    response_text = "ã”ã‚ã‚“ãªã•ã„ã€ã†ã¾ãæ€ã„å‡ºã›ã¾ã›ã‚“ã§ã—ãŸã€‚"
                    append_history("assistant", response_text)
        else:
            logger.info("[STEP] GPTå¿œç­”ãŒæ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ç”Ÿã®å¿œç­”ã‚’è¿”å´")
            append_history("assistant", response_text)

        final_response, final_emotion = generate_emotion_from_prompt_with_context(
            user_input=user_input,
            emotion_structure=emotion_data.get("æ§‹æˆæ¯”", {}),
            best_match=get_best_match(emotion_data)
        )
        append_history("assistant", final_response)

        parsed_emotion_data = save_response_to_memory(final_response)
        if parsed_emotion_data:
            write_structured_emotion_data(parsed_emotion_data)
            emotion_to_merge = parsed_emotion_data.get("æ§‹æˆæ¯”", final_emotion)
        else:
            logger.warning("âš  æ§‹é€ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•— â†’ ç›´æ¥ç”Ÿæˆã—ãŸæ„Ÿæƒ…æ§‹æˆæ¯”ã‚’ä½¿ç”¨")
            emotion_to_merge = final_emotion

        latest_emotion = load_current_emotion()
        merged_emotion = merge_emotion_vectors(
            current=latest_emotion,
            new=emotion_to_merge,
            weight_new=0.3,
            decay_factor=0.9,
            normalize=True
        )
        save_current_emotion(merged_emotion)
        summary = summarize_feeling(merged_emotion)

        if background_tasks:
            background_tasks.add_task(process_and_cleanup_emotion_data, final_response)

        return {
            "response": final_response,
            "summary": summary
        }

    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        return PlainTextResponse("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", status_code=500)


def store_emotion_structured_data(response_text: str):
    logger.info("ğŸ§© store_emotion_structured_data() ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")
    parsed_emotion_data = save_response_to_memory(response_text)
    if parsed_emotion_data:
        write_structured_emotion_data(parsed_emotion_data)
    else:
        logger.warning("âš  èƒŒæ™¯ã‚¿ã‚¹ã‚¯ï¼šæ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ãŸãŸã‚ã€ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—")


def process_and_cleanup_emotion_data(response_text: str):
    logger.info("ğŸ”„ æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã¨å¿˜å´å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    store_emotion_structured_data(response_text)
    logger.info("ğŸ§¹ æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¾Œã€å¿˜å´å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™")
    run_oblivion_cleanup_all()
    logger.info("âœ… æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼‹å¿˜å´å‡¦ç† å®Œäº†")
