import sys
import os
import re
import requests
from fastapi import FastAPI, HTTPException, Form, BackgroundTasks
from fastapi.responses import FileResponse, PlainTextResponse
from pydantic import BaseModel

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), "module"))

from module.llm.llm_client import (
    generate_emotion_from_prompt_with_context,
    generate_gpt_response_from_history,
)
from module.utils.utils import load_history, append_history, logger
from module.emotion.main_emotion import save_response_to_memory, write_structured_emotion_data
from module.emotion.emotion_stats import (
    load_current_emotion,
    merge_emotion_vectors,
    save_current_emotion,
    summarize_feeling,
)
from module.response.main_response import find_response_by_emotion, get_best_match, collect_all_category_responses
from module.oblivion.oblivion_module import run_oblivion_cleanup_all
from module.voice.voice_processing import synthesize_voice

app = FastAPI()

class UserMessage(BaseModel):
    message: str

# å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ«å°¾ã®JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ï¼ˆUIè¡¨ç¤ºç”¨ï¼‰
def sanitize_output_for_display(text: str) -> str:
    pattern = r'({.*})'
    matches = re.findall(pattern, text, re.DOTALL)
    if matches:
        return text.replace(matches[-1], '').strip()
    return text.strip()

@app.get("/")
def get_ui():
    return FileResponse("static/index.html")

@app.get("/history")
def get_history():
    try:
        return {"history": load_history()}
    except Exception:
        logger.exception("å±¥æ­´å–å¾—ä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        raise HTTPException(status_code=500, detail="å±¥æ­´ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

@app.post("/chat")
async def chat(
    message: str = Form(...),
    background_tasks: BackgroundTasks | None = None
):
    logger.debug("âœ… /chat ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«åˆ°é”")
    logger.info("âœ… debug() å®Ÿè¡Œæ¸ˆã¿")

    try:
        user_input = message
        logger.debug(f"ğŸ“¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å–å¾—å®Œäº†: {user_input}")

        # å±¥æ­´è¿½åŠ ï¼ˆuserï¼‰
        append_history("user", user_input)
        logger.debug("ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´è¿½åŠ å®Œäº†")

        # ç¾åœ¨æ„Ÿæƒ…ãƒ­ãƒ¼ãƒ‰
        current_emotion = load_current_emotion()
        logger.debug(f"ğŸ¯ [INFO] ç¾åœ¨æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«: {current_emotion}")

        # ç›´è¿‘å±¥æ­´ãƒ™ãƒ¼ã‚¹ã®ä»®å¿œç­”ï¼ˆæ§‹é€ æŠ½å‡ºã®è¶³ãŒã‹ã‚Šï¼‰
        response_text = generate_gpt_response_from_history()
        logger.info(f"ğŸ“¨ GPTå¿œç­”:\n{response_text}")

        # æ„Ÿæƒ…ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¤œç´¢ï¼ˆå¿œç­”ã®å‘¼ã³å‡ºã—æœ€é©åŒ–ï¼‰
        emotion_data = find_response_by_emotion()

        if emotion_data.get("type") == "extracted":
            logger.info("[STEP] GPTå¿œç­”ã‹ã‚‰æ§‹æˆæ¯”ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—æ¸ˆ")
            best_match = get_best_match(emotion_data)

            if best_match:
                logger.info("[STEP] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãƒãƒƒãƒã—ãŸå¿œç­”ã‚’å–å¾—")
                response_text = best_match.get("å¿œç­”", "")
                append_history("assistant", response_text)
            else:
                from datetime import datetime
                dominant_emotion = next(iter(emotion_data["æ§‹æˆæ¯”"]), None)
                if dominant_emotion:
                    today = datetime.now().strftime("%Y-%m-%d")
                    matched = collect_all_category_responses(
                        emotion_name=dominant_emotion,
                        date_str=today
                    )
                    for cat in ["short", "intermediate", "long"]:
                        if matched.get(cat):
                            response_text = matched[cat].get("å¿œç­”", "")
                            logger.info(f"[STEP] å±¥æ­´ã‹ã‚‰ {cat} ã‚«ãƒ†ã‚´ãƒªã®å¿œç­”ã‚’è¿”å´")
                            append_history("assistant", response_text)
                            break

                if not response_text:
                    logger.warning("[WARN] å±¥æ­´ã«ã‚‚ä¸€è‡´ã™ã‚‹å¿œç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    response_text = "ã”ã‚ã‚“ãªã•ã„ã€ã†ã¾ãæ€ã„å‡ºã›ã¾ã›ã‚“ã§ã—ãŸã€‚"
                    append_history("assistant", response_text)
        else:
            logger.info("[STEP] æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ç”Ÿã®å¿œç­”ã‚’è¿”å´")
            append_history("assistant", response_text)

        # æœ€çµ‚å¿œç­”ï¼šæ„Ÿæƒ…æ§‹æˆæ¯”ã¨å‚ç…§ã‚’è¸ã¾ãˆã¦ç”Ÿæˆ
        final_response, final_emotion = generate_emotion_from_prompt_with_context(
            user_input=user_input,
            emotion_structure=emotion_data.get("æ§‹æˆæ¯”", {}),
            best_match=get_best_match(emotion_data)
        )
        append_history("assistant", final_response)

        # éŸ³å£°åˆæˆï¼ˆVoiceVoxï¼‰
        voice_settings = final_emotion.get("voicevox_settings")
        if voice_settings:
            audio_binary = synthesize_voice(final_response, voice_settings)
            with open("output.wav", "wb") as f:
                f.write(audio_binary)

        # æ§‹é€ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ»ä¿å­˜
        parsed_emotion_data = save_response_to_memory(final_response)
        if parsed_emotion_data:
            write_structured_emotion_data(parsed_emotion_data)
            emotion_to_merge = parsed_emotion_data.get("æ§‹æˆæ¯”", final_emotion)
        else:
            logger.warning("âš  æ§‹é€ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•— â†’ ç›´æ¥ç”Ÿæˆã—ãŸæ„Ÿæƒ…æ§‹æˆæ¯”ã‚’ä½¿ç”¨")
            emotion_to_merge = final_emotion

        # ç¾åœ¨æ„Ÿæƒ…ã®æ›´æ–°
        latest_emotion = load_current_emotion()
        merged_emotion = merge_emotion_vectors(
            current=latest_emotion,
            new=emotion_to_merge,
            weight_new=0.3,
            decay_factor=0.9,
            normalize=True
        )
        save_current_emotion(merged_emotion)
        summary = summarize_feeling(merged_emotion)

        # èƒŒæ™¯ã§å¿˜å´å‡¦ç†
        if background_tasks:
            background_tasks.add_task(process_and_cleanup_emotion_data, final_response)

        visible_response = sanitize_output_for_display(final_response)

        return {
            "response": visible_response,
            "summary": summary
        }

    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        return PlainTextResponse("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", status_code=500)

def store_emotion_structured_data(response_text: str):
    logger.info("ğŸ§© store_emotion_structured_data() ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")
    parsed_emotion_data = save_response_to_memory(response_text)
    if parsed_emotion_data:
        write_structured_emotion_data(parsed_emotion_data)
    else:
        logger.warning("âš  èƒŒæ™¯ã‚¿ã‚¹ã‚¯ï¼šæ§‹é€ ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ãŸãŸã‚ã€ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—")

def process_and_cleanup_emotion_data(response_text: str):
    logger.info("ğŸ”„ æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã¨å¿˜å´å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    store_emotion_structured_data(response_text)
    logger.info("ğŸ§¹ æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¾Œã€å¿˜å´å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™")
    run_oblivion_cleanup_all()
    logger.info("âœ… æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼‹å¿˜å´å‡¦ç† å®Œäº†")

# èµ·å‹•æ™‚ã®ãƒã‚§ãƒƒã‚¯å‡¦ç†
@app.on_event("startup")
async def on_startup():
    logger.info("ğŸš€ ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•ãƒã‚§ãƒƒã‚¯é–‹å§‹")
    try:
        resp = requests.get("http://localhost:50021/speakers")
        resp.raise_for_status()
        logger.info("ğŸ”ˆ VoiceVoxã‚¨ãƒ³ã‚¸ãƒ³ã«æ¥ç¶šæˆåŠŸ")
    except Exception as e:
        logger.warning(f"âš ï¸ VoiceVoxã‚¨ãƒ³ã‚¸ãƒ³ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
    logger.info("âœ… èµ·å‹•å‰ãƒã‚§ãƒƒã‚¯å®Œäº†")
