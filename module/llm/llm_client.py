from openai import OpenAI
import re
import json
import os
import threading
from datetime import datetime

from module.utils.utils import load_system_prompt_cached, load_dialogue_prompt, logger
from module.params import OPENAI_MODEL, OPENAI_TEMPERATURE, OPENAI_TOP_P, OPENAI_MAX_TOKENS
from module.emotion.basic_personality import get_top_long_emotions

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆæœ«å°¾ã‹ã‚‰JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
# Extract trailing JSON block from response
def extract_emotion_json_block(response_text: str) -> dict | None:
    logger.info("ğŸ§ª JSONæŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹")

    # ãƒ‘ã‚¿ãƒ¼ãƒ³1ï¼š```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆæ¨å¥¨å½¢å¼ï¼‰
    match = re.search(r"```json\s*({.*?})\s*```", response_text, re.DOTALL)
    if match:
        try:
            parsed = json.loads(match.group(1))
            logger.info("âœ… Markdownå½¢å¼ã§ã®JSONæŠ½å‡ºæˆåŠŸ")
            return parsed
        except json.JSONDecodeError as e:
            logger.warning(f"âš  Markdown JSONæŠ½å‡ºå¤±æ•—: {e}")

    # ãƒ‘ã‚¿ãƒ¼ãƒ³2ï¼šæ™®é€šã® {...} ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆæ—§å½¢å¼ï¼‰
    matches = re.findall(r'({.*})', response_text, re.DOTALL)
    for raw in reversed(matches):
        try:
            parsed = json.loads(raw)
            logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ­£è¦è¡¨ç¾ã§ã®JSONæŠ½å‡ºæˆåŠŸ")
            return parsed
        except json.JSONDecodeError:
            continue

    logger.warning("âŒ JSONæŠ½å‡ºå¤±æ•—ã€‚response_textã¯æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ã‚ã‚Š")
    return None


# å‚ç…§ãƒ‡ãƒ¼ã‚¿ï¼ˆbest_matchï¼‰ã‚’åŠ å‘³ã—ã¦æœ€çµ‚å¿œç­”ã‚’ç”Ÿæˆï¼ˆLLMã¯ã“ã“ã§ã®ã¿å‘¼ã¶ï¼‰
# Generate final response using best_match reference (single LLM call)
def generate_emotion_from_prompt_with_context(
    user_input: str,
    emotion_structure: dict,
    best_match: dict | None
) -> tuple[str, dict]:
    generation_time = datetime.now().strftime("%Y%m%d%H%M%S")

    system_prompt = (
        load_system_prompt_cached()
        + "\n\n"
        + load_dialogue_prompt()
    )

    # äººæ ¼å‚¾å‘
    top4_personality = get_top_long_emotions()
    personality_text = "\nã€äººæ ¼å‚¾å‘ã€‘\nã“ã®AIã¯ä»¥ä¸‹ã®æ„Ÿæƒ…ã‚’æŒã¤å‚¾å‘ãŒã‚ã‚Šã¾ã™ï¼š\n"
    if top4_personality:
        for emotion, count in top4_personality:
            personality_text += f"ãƒ»{emotion}ï¼ˆ{count}å›ï¼‰\n"
    else:
        personality_text += "å‚¾å‘æƒ…å ±ãŒã¾ã ååˆ†ã«ã‚ã‚Šã¾ã›ã‚“ã€‚\n"

    # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢ï¼ˆbest_matchãŒç„¡ã„å ´åˆã§ã‚‚è¿½åŠ ã®LLMå‘¼ã³å‡ºã—ã¯ã—ãªã„ï¼‰
    reference_text = "\n\nã€AIè‡ªèº«ã®è¨˜æ†¶ï¼ˆå‚è€ƒæ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ï¼‰ã€‘\n"
    if best_match is None:
        reference_text += "å‚ç…§å¯èƒ½ãªè¨˜æ†¶ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚é€šå¸¸ã®æ–¹é‡ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚\n"
    else:
        from module.response.main_response import collect_all_category_responses

        emotion_name = best_match.get("emotion")
        date_str = best_match.get("date")
        history_data = collect_all_category_responses(emotion_name, date_str)

        reference_emotions = []
        for category in ["short", "intermediate", "long"]:
            data = history_data.get(category)
            if data:
                reference_emotions.append(data)

        reference_text += (
            "ä»¥ä¸‹ã¯ã€ã‚ãªãŸè‡ªèº«ï¼ˆAIï¼‰ãŒã“ã‚Œã¾ã§ã«çµŒé¨“ãƒ»è¨˜éŒ²ã—ãŸæ„Ÿæƒ…ã®è¨˜æ†¶ã§ã™ã€‚\n"
            "å„ã‚±ãƒ¼ã‚¹ã¯å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®å¯¾è©±ã«åŸºã¥ã„ã¦è¨˜éŒ²ã•ã‚ŒãŸã‚‚ã®ã§ã‚ã‚Šã€ã‚ãªãŸã®å†…çš„ãªè¨˜æ†¶ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n"
            "ã“ã‚Œã‚‰ã®è¨˜æ†¶ã‚’å‚ç…§ã—ãªãŒã‚‰ã€è‡ªç„¶ã§ä¸€è²«æ€§ã®ã‚ã‚‹å¿œç­”ã‚’æ§‹æˆã—ã¦ãã ã•ã„ã€‚\n"
        )
        for i, item in enumerate(reference_emotions, 1):
            reference_text += f"\nâ— è¨˜æ†¶ã‚±ãƒ¼ã‚¹{i}\n"
            reference_text += f"ä¸»æ„Ÿæƒ…: {item.get('ä¸»æ„Ÿæƒ…')}\n"
            reference_text += f"æ§‹æˆæ¯”: {item.get('æ§‹æˆæ¯”')}\n"
            reference_text += f"çŠ¶æ³: {item.get('çŠ¶æ³')}\n"
            reference_text += f"å¿ƒç†åå¿œ: {item.get('å¿ƒç†åå¿œ')}\n"
            reference_text += f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(item.get('keywords', []))}\n"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = (
        f"{personality_text}\n"
        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€: {user_input}\n"
        f"{reference_text}\n\n"
        f"ã€æŒ‡ç¤ºã€‘ä¸Šè¨˜ã®ï¼ˆã‚ã‚Œã°ï¼‰æ„Ÿæƒ…å‚ç…§ãƒ‡ãƒ¼ã‚¿ã¨äººæ ¼å‚¾å‘ã‚’å‚è€ƒã«ã€emotion_promptã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
        f"è‡ªç„¶ãªå¿œç­” + æ§‹æˆæ¯” + JSONå½¢å¼ã®æ„Ÿæƒ…æ§‹é€ ã®é †ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )

    try:
        # LLMå‘¼ã³å‡ºã—ã¯ã“ã“ã ã‘
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=OPENAI_MAX_TOKENS,
            temperature=OPENAI_TEMPERATURE,
            top_p=OPENAI_TOP_P
        )

        # LLMã‹ã‚‰ã®ç”Ÿãƒ†ã‚­ã‚¹ãƒˆå¿œç­”
        full_response = response.choices[0].message.content.strip()

        # ğŸ¯ JSONæŠ½å‡ºï¼ˆLLMå‡ºåŠ›å¾Œã«å®Ÿè¡Œï¼‰
        emotion_data = extract_emotion_json_block(full_response)

        if emotion_data:
            emotion_data["date"] = generation_time

            # æ§‹æˆæ¯”ãŒæ–‡å­—åˆ—ã§æ¥ã‚‹å ´åˆã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º
            if "æ§‹æˆæ¯”" in emotion_data:
                while isinstance(emotion_data["æ§‹æˆæ¯”"], str):
                    try:
                        emotion_data["æ§‹æˆæ¯”"] = json.loads(emotion_data["æ§‹æˆæ¯”"])
                    except json.JSONDecodeError:
                        break

            logger.debug(f"ğŸ§ª [DEBUG] æ§‹æˆæ¯” type: {type(emotion_data.get('æ§‹æˆæ¯”'))}")
            logger.debug(f"ğŸ§ª [DEBUG] æ§‹æˆæ¯” å†…å®¹: {emotion_data.get('æ§‹æˆæ¯”')}")

            # æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã®ä¿å­˜ãƒ»æ¸›è¡°æ›´æ–°ã¯åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§
            if "æ§‹æˆæ¯”" in emotion_data and isinstance(emotion_data["æ§‹æˆæ¯”"], dict):
                threading.Thread(
                    target=run_emotion_update_pipeline,
                    args=(emotion_data["æ§‹æˆæ¯”"],)
                ).start()

            # è¡¨ç¤ºç”¨ï¼šJSONãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ã—ã¦è‡ªç„¶æ–‡ã®ã¿è¿”ã™
            clean_response = re.sub(r"```json\s*\{.*?\}\s*```", "", full_response, flags=re.DOTALL).strip()
            return clean_response, emotion_data

        # JSONãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return full_response, {}

    except Exception as e:
        logger.error(f"[ERROR] å¿œç­”ç”Ÿæˆå¤±æ•—: {e}")
        return "å¿œç­”ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", {}


# æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒãƒ¼ã‚¸ï¼†ä¿å­˜ï¼†è¦ç´„ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
# Merge and persist emotion vector (background)
def run_emotion_update_pipeline(new_vector: dict) -> tuple[str, dict]:
    try:
        from module.emotion.emotion_stats import (
            load_current_emotion,
            merge_emotion_vectors,
            save_current_emotion,
            summarize_feeling
        )

        current = load_current_emotion()
        logger.debug(f"[DEBUG] current type: {type(current)}")
        logger.debug(f"[DEBUG] new_vector type: {type(new_vector)}")
        logger.debug(f"[DEBUG] new_vector content: {new_vector}")

        merged = merge_emotion_vectors(current, new_vector)
        save_current_emotion(merged)
        summary = summarize_feeling(merged)
        return "æ„Ÿæƒ…ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚", summary

    except Exception as e:
        logger.error(f"[ERROR] æ„Ÿæƒ…æ›´æ–°å‡¦ç†ã«å¤±æ•—: {e}")
        return "æ„Ÿæƒ…æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", {}
