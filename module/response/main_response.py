from llm_client import generate_emotion_from_prompt_simple as estimate_emotion, generate_emotion_from_prompt_with_context, extract_emotion_summary
from response.response_index import load_and_categorize_index, extract_best_reference, find_best_match_by_composition
from utils import logger
from main_memory import handle_emotion, save_emotion_sample  # è¿½åŠ 
import json

def load_emotion_by_date(path, target_date):
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)

        if isinstance(data, list):
            for item in reversed(data):
                if item.get("date") == target_date:
                    return item

        elif isinstance(data, dict) and "å±¥æ­´" in data:
            for item in reversed(data["å±¥æ­´"]):
                if item.get("date") == target_date:
                    return item
    except Exception as e:
        logger.error(f"[ERROR] æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
    return None

def run_response_pipeline(user_input: str) -> tuple[str, dict]:
    initial_emotion = {}
    reference_emotions = []
    best_match = None

    try:
        print("âœã‚¹ãƒ†ãƒƒãƒ—â‘ : æ„Ÿæƒ…æ¨å®š é–‹å§‹")
        raw_response, initial_emotion = estimate_emotion(user_input)
        summary_str = ", ".join([f"{k}:{v}%" for k, v in initial_emotion.get("æ§‹æˆæ¯”", {}).items()])
        print(f"ğŸ’«æ¨å®šå¿œç­”å†…å®¹ï¼ˆrawï¼‰: {raw_response}")
        print(f"ğŸ’æ§‹æˆæ¯”ï¼ˆä¸»æ„Ÿæƒ…: {initial_emotion.get('ä¸»æ„Ÿæƒ…', 'æœªå®šç¾©')}ï¼‰: (æ§‹æˆæ¯”: {summary_str})")

        # âœ… GPTæ¨å®šçµæœã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«è¨˜éŒ²
        save_emotion_sample(user_input, raw_response, initial_emotion.get("æ§‹æˆæ¯”", {}))

    except Exception as e:
        logger.error(f"[ERROR] æ„Ÿæƒ…æ¨å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise

    try:
        print("âœã‚¹ãƒ†ãƒƒãƒ—â‘¡: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å…¨ä»¶èª­ã¿è¾¼ã¿ é–‹å§‹")
        categorized = load_and_categorize_index()
        count_long = len(categorized.get("long", []))
        count_intermediate = len(categorized.get("intermediate", []))
        count_short = len(categorized.get("short", []))
        print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»¶æ•°: short={count_short}ä»¶, intermediate={count_intermediate}ä»¶, long={count_long}ä»¶")
    except Exception as e:
        logger.error(f"[ERROR] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise

    try:
        print("âœã‚¹ãƒ†ãƒƒãƒ—â‘¢: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ï¼†æ§‹æˆæ¯”é¡ä¼¼ æŠ½å‡º é–‹å§‹")
        for category in ["short", "intermediate", "long"]:
            refer = extract_best_reference(initial_emotion, categorized.get(category, []), category)
            if refer:
                emotion_data = refer.get("emotion", {})
                path = emotion_data.get("ä¿å­˜å…ˆ")
                date = emotion_data.get("date")
                full_emotion = load_emotion_by_date(path, date) if path and date else None
                if full_emotion:
                    keywords = emotion_data.get("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", [])
                    match_info = refer.get("match_info", "")
                    reference_emotions.append({
                        "emotion": full_emotion,
                        "source": refer.get("source"),
                        "match_info": match_info
                    })
        print(f"ğŸ“Œ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã«ã‚ˆã‚‹å‚ç…§æ„Ÿæƒ…ä»¶æ•°: {len(reference_emotions)}ä»¶")

        best_match = find_best_match_by_composition(initial_emotion["æ§‹æˆæ¯”"], [r["emotion"] for r in reference_emotions])

        if best_match is None:
            print("âœã‚¹ãƒ†ãƒƒãƒ—â‘£: ä¸€è‡´ãªã— â†’ ä»®å¿œç­”ã‚’ä½¿ç”¨")
            final_response = raw_response
            response_emotion = initial_emotion
        else:
            print("âœã‚¹ãƒ†ãƒƒãƒ—â‘£: å¿œç­”ç”Ÿæˆã¨æ„Ÿæƒ…å†æ¨å®š é–‹å§‹")
            final_response, response_emotion = generate_emotion_from_prompt_with_context(user_input, [best_match])

    except Exception as e:
        logger.error(f"[ERROR] GPTå¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise

    try:
        print("âœã‚¹ãƒ†ãƒƒãƒ—â‘¤: å¿œç­”ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º å®Œäº†")
        print("ğŸ’¬ æœ€çµ‚å¿œç­”å†…å®¹ï¼ˆå†æ²ï¼‰:")
        print(f"ğŸ’­{final_response.strip()}")
        main_emotion = response_emotion.get('ä¸»æ„Ÿæƒ…', 'æœªå®šç¾©')
        final_summary = ", ".join([f"{k}:{v}%" for k, v in response_emotion.get("æ§‹æˆæ¯”", {}).items()])
        print(f"ğŸ’æ§‹æˆæ¯”ï¼ˆä¸»æ„Ÿæƒ…: {main_emotion}ï¼‰: {final_summary}")

        if best_match:
            print("ğŸ“Œ å‚ç…§æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿:")
            for idx, emo_entry in enumerate(reference_emotions, start=1):
                emo = emo_entry["emotion"]
                ratio = emo.get("æ§‹æˆæ¯”", {})
                summary_str = ", ".join([f"{k}:{v}%" for k, v in ratio.items()])
                match_info = emo_entry.get("match_info", "")
                source = emo_entry.get("source", "ä¸æ˜")
                print(f"  [{idx}] {summary_str} | çŠ¶æ³: {emo.get('çŠ¶æ³', '')} | ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(emo.get('keywords', []))}ï¼ˆ{match_info}ï½œ{source}ï¼‰")
        else:
            print("ğŸ“Œ å‚ç…§æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿: å‚ç…§ãªã—")

        # âœ… æ„Ÿæƒ…ä¿å­˜ç”¨ã«æ¸¡ã™ï¼ˆemotion_index ç”¨ï¼‰
        response_emotion["emotion_vector"] = response_emotion.get("æ§‹æˆæ¯”", {})
        handle_emotion(response_emotion, user_input=user_input, response_text=final_response)

        return final_response, response_emotion
    except Exception as e:
        logger.error(f"[ERROR] æœ€çµ‚å¿œç­”ãƒ­ã‚°å‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise

