#module/response/response_index.py
import json
import os
import re
from bson import ObjectId

from module.utils.utils import logger
from module.mongo.mongo_client import get_mongo_client
from module.llm.llm_client import generate_gpt_response_from_history
from module.params import emotion_map

# æ§‹æˆæ¯”ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å—ã‘å–ã‚‹æ¤œç´¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
# Search interface that receives composition and keywords
def search_index_response(composition: dict, keywords: list[str]) -> dict:
    composition = emotion_structure.get("æ§‹æˆæ¯”", {})
    # Extract composition ratio
    keywords = emotion_structure.get("keywords", [])
    # Extract keywords

# è‹±èªã®æ„Ÿæƒ…åã‚’æ—¥æœ¬èªã«å¤‰æ›
# Convert emotion name from English to Japanese
def translate_emotion(emotion): 
    return emotion_map.get(emotion, emotion)

# å—ã‘å–ã£ãŸæ§‹æˆæ¯”ï¼ˆéƒ¨åˆ†çš„ï¼‰ã‚’ emotion_map é †ã«æ•´å½¢ï¼ˆä¸è¶³ã¯0ã§åŸ‹ã‚ã‚‹ï¼‰
# Normalize partial composition vector in the order of emotion_map (fill missing with 0)
def normalize_composition_vector(partial_composition: dict) -> dict: 
    return {jp_emotion: partial_composition.get(jp_emotion, 0) for jp_emotion in emotion_map.values()}

# MongoDBã‹ã‚‰emotion_indexã‚’å–å¾—
# Load emotion_index from MongoDB
def load_index():
    logger.debug("ğŸ“¥ [STEP] MongoDBã‹ã‚‰emotion_indexã‚’å–å¾—ã—ã¾ã™...")
    try:
        client = get_mongo_client()
        if client is None:
            raise ConnectionError("MongoDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        # Failed to obtain MongoDB client
        db = client["emotion_db"]
        collection = db["emotion_index"]
        data = list(collection.find({}))
        logger.info(f"âœ… [SUCCESS] emotion_index ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(data)}")
        # Number of emotion_index records
        return data
    except Exception as e:
        logger.warning(f"âŒ [ERROR] MongoDBã‹ã‚‰ã®å–å¾—ã«å¤±æ•—: {e}")
        # Failed to retrieve from MongoDB
        return []

# å–å¾—ã—ãŸemotion_indexã‚’ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«åˆ†é¡
# Categorize loaded emotion_index data by category
def load_and_categorize_index():
    logger.info("ğŸ“‚ [STEP] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«åˆ†é¡ã—ã¾ã™...")
    all_index = load_index()
    categorized = {"long": [], "intermediate": [], "short": []}

    for item in all_index:
        category = item.get("category", "unknown")
        if category in categorized:
            categorized[category].append(item)

    for cat, items in categorized.items():
        logger.debug(f"ğŸ“Š {cat}ã‚«ãƒ†ã‚´ãƒª: {len(items)} ä»¶")
        # Number of records per category

    return categorized

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
# Perform keyword filtering on categorized emotion_index
def filter_by_keywords(index_data, input_keywords):
    logger.info(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨: {input_keywords}")
    filtered = [item for item in index_data if set(item.get("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", [])) & set(input_keywords)]
    logger.info(f"ğŸ¯ ä¸€è‡´ä»¶æ•°: {len(filtered)}")
    return filtered

# è‹±èªã®æ„Ÿæƒ…åã‚’æ—¥æœ¬èªã«å¤‰æ›ï¼ˆé‡è¤‡ã‚ã‚Šï¼‰
# Convert English emotion name to Japanese (duplicate)
def translate_emotion(emotion: str) -> str:
    return emotion_map.get(emotion, emotion)

# æ§‹æˆæ¯”ã®ä¸€è‡´ã‚¹ã‚³ã‚¢ã«åŸºã¥ãæœ€ã‚‚è¿‘ã„å€™è£œã‚’é¸å‡º
# Find best match based on similarity of emotion composition
def find_best_match_by_composition(current_composition, candidates):
    logger.info(f"ğŸ” æ§‹æˆæ¯”ãƒãƒƒãƒãƒ³ã‚°å¯¾è±¡æ•°: {len(candidates)}")
    logger.debug(f"[DEBUG] current_composition type: {type(current_composition)}")
    logger.debug(f"[DEBUG] current_composition value: {current_composition}")

    # ğŸ”¸ ã‚¹ã‚³ã‚¢è¨ˆç®—é–¢æ•°
    # Score calculation function
    def calculate_composition_score(base: dict, target: dict) -> float:
        shared_keys = set(base.keys()) & set(target.keys())
        score = 0.0
        for key in shared_keys:
            diff = abs(base.get(key, 0) - target.get(key, 0))
            score += (100 - diff)
        return score / len(shared_keys) if shared_keys else 0.0

    # ğŸ”¸ å€™è£œã®é©æ ¼æ€§åˆ¤å®š
    # Validity check for candidate
    def is_valid_candidate(candidate_comp, base_comp):
        logger.debug(f"[DEBUG] candidate_comp type: {type(candidate_comp)} / base_comp type: {type(base_comp)}")
        logger.debug(f"[DEBUG] candidate_comp: {candidate_comp}")
        logger.debug(f"[DEBUG] base_comp: {base_comp}")

        try:
            base_filtered = {k: v for k, v in base_comp.items() if v > 5}
            cand_filtered = {k: v for k, v in candidate_comp.items() if v > 5}
        except AttributeError as e:
            logger.warning(f"[ERROR] .items() å‘¼ã³å‡ºã—å¤±æ•—: {e}")
            return False

        base_keys = list(base_filtered.keys())
        shared_keys = set(base_filtered.keys()) & set(cand_filtered.keys())
        required_match = max(len(base_keys) - 1, 1)
        matched = 0

        for key in shared_keys:
            diff = abs(base_filtered.get(key, 0) - cand_filtered.get(key, 0))
            if diff <= 30:
                matched += 1

        return matched >= required_match

    valid_candidates = [
        c for c in candidates if is_valid_candidate(c["æ§‹æˆæ¯”"], current_composition)
    ]

    logger.info(f"âœ… æœ‰åŠ¹ãªå€™è£œæ•°: {len(valid_candidates)}")
    if not valid_candidates:
        logger.warning("âŒ æ§‹æˆæ¯”ãƒãƒƒãƒå€™è£œãªã—")
        return None

    # ğŸ”¸ æœ€ã‚‚ã‚¹ã‚³ã‚¢ãŒé«˜ã„å€™è£œã‚’é¸å‡º
    # Select candidate with highest similarity score
    best = max(valid_candidates, key=lambda c: calculate_composition_score(current_composition, c["æ§‹æˆæ¯”"]))

    # ğŸ”¸ çµæœã®ç¿»è¨³è¡¨ç¤º
    # Translate and log best match
    jp_emotion = translate_emotion(best.get("emotion", "Unknown"))
    logger.info(f"ğŸ… æœ€ã‚‚æ§‹æˆæ¯”ãŒè¿‘ã„å€™è£œã‚’é¸å‡º: {jp_emotion}")

    return best

