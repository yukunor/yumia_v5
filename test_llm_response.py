import sys
import os

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), "module"))

from llm.llm_client import (
    generate_emotion_from_prompt_with_context,
    extract_emotion_summary
)
from memory.current_emotion import load_current_emotion  # ç¾åœ¨ã®æ°—åˆ†ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—

if __name__ == "__main__":
    user_input = "ä»Šæ—¥ã¯ãªã‚“ã ã‹ä¸å®‰ãªæ°—åˆ†ã§ã™ã€‚"

    # ç¾åœ¨ã®æ„Ÿæƒ…çŠ¶æ…‹ã‚’å–å¾—ï¼ˆãƒŸã‚­ã‚·ãƒ³ã‚°ã«ä½¿ã†å‰æï¼‰
    current_emotion = load_current_emotion()

    print("ğŸ” LLMå¿œç­”ã¨æ„Ÿæƒ…æ§‹é€ ã®å–å¾—ã‚’é–‹å§‹...")
    response, emotion_data = generate_emotion_from_prompt_with_context(user_input, current_emotion)

    print("\n=== ğŸ—£ å¿œç­”å†…å®¹ ===")
    print(response)

    print("\n=== ğŸ§  æ„Ÿæƒ…æ§‹é€  ===")
    for k, v in emotion_data.items():
        print(f"{k}: {v}")

    print("\n=== ğŸ“Š æ§‹æˆæ¯”ã‚µãƒãƒª ===")
    summary = extract_emotion_summary(emotion_data, emotion_data.get("ä¸»æ„Ÿæƒ…", "æœªå®šç¾©"))
    print(summary)
